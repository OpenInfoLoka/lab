{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_html_data(data_dir):\n",
    "    import binascii\n",
    "    f = open(data_dir)\n",
    "    data1 = f.read()\n",
    "    res = [ format(ord(i), 'b')  for i in data1]\n",
    "    res = ['00' + x if len(x) == 6 else '0' + x for x in res]\n",
    "    res2 =[ np.fromstring(i,'u1') - ord('0') for i in res]\n",
    "    f.close()\n",
    "    return res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html = np.asarray(load_html_data('test.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = html[:120].astype(np.float32)\n",
    "n_x = train_x.shape[1]\n",
    "n_hidden = [50]\n",
    "n_z = 2\n",
    "n_y = n_x\n",
    "\n",
    "frames  = train_x.shape[0]\n",
    "n_batch = 6\n",
    "seq_length = frames / n_batch\n",
    "\n",
    "split_x = np.vsplit(train_x, n_batch)\n",
    "n_input = 20\n",
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.models.rnn import rnn, rnn_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "\n",
    "class BasicCell(object):\n",
    "    \n",
    "    def __init__(self, num_units, input_size=None):\n",
    "        if input_size is not None:\n",
    "            logging.warn(\"%s: The input_size parameter is deprecated.\" % self)\n",
    "        self._num_units = num_units\n",
    "    \n",
    "    def zero_state(self, dtype):\n",
    "        zeros = array_ops.zeros(\n",
    "            array_ops.pack([1, self._num_units]), dtype=dtype)\n",
    "        zeros.set_shape([None, self._num_units])\n",
    "        return zeros\n",
    "    \n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        with vs.variable_scope(scope or type(self).__name__):\n",
    "            output = tanh(self.linear([inputs, state], self._num_units, False, scope=scope))\n",
    "        return output, output\n",
    "    \n",
    "    def linear(self, args, output_size, bias, bias_start=0.0, scope=None):\n",
    "        if args is None or (isinstance(args, (list, tuple)) and not args):\n",
    "            raise ValueError(\"`args` must be specified\")\n",
    "        if not isinstance(args, (list, tuple)):\n",
    "            args = [args]\n",
    "        # Calculate the total size of arguments on dimension 1.\n",
    "        total_arg_size = 0\n",
    "        shapes = [a.get_shape().as_list() for a in args]\n",
    "        for shape in shapes:\n",
    "            if len(shape) != 2:\n",
    "                raise ValueError(\"Linear is expecting 2D arguments: %s\" % str(shapes))\n",
    "            if not shape[1]:\n",
    "                raise ValueError(\"Linear expects shape[1] of arguments: %s\" % str(shapes))\n",
    "            else:\n",
    "                total_arg_size += shape[1]\n",
    "\n",
    "        # Now the computation.\n",
    "        with vs.variable_scope(scope or \"Linear\"):\n",
    "            matrix_in = vs.get_variable(\"MatrixIn\", [shapes[0][1], shapes[1][1]])\n",
    "            matrix_state = vs.get_variable(\"MatrixState\", [shapes[1][1], output_size])\n",
    "            if len(args) == 1:\n",
    "                res = math_ops.matmul(args[0], matrix)\n",
    "            else:\n",
    "                res = math_ops.add(math_ops.matmul(args[0], matrix_in), math_ops.matmul(args[1], matrix_state))\n",
    "            if not bias:\n",
    "                return res\n",
    "            bias_term = vs.get_variable(\n",
    "            \"Bias\", [output_size],\n",
    "            initializer=init_ops.constant_initializer(bias_start))\n",
    "            return math_ops.add(res, bias_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "\n",
    "def sigmoid_cross_entropy_with_logits(logits, targets, name=None):\n",
    "  \"\"\"Computes sigmoid cross entropy given `logits`.\n",
    "\n",
    "  Measures the probability error in discrete classification tasks in which each\n",
    "  class is independent and not mutually exclusive.  For instance, one could\n",
    "  perform multilabel classification where a picture can contain both an elephant\n",
    "  and a dog at the same time.\n",
    "\n",
    "  For brevity, let `x = logits`, `z = targets`.  The logistic loss is\n",
    "\n",
    "        z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n",
    "      = z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n",
    "      = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n",
    "      = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n",
    "      = (1 - z) * x + log(1 + exp(-x))\n",
    "      = x - x * z + log(1 + exp(-x))\n",
    "\n",
    "  To ensure stability and avoid overflow, the implementation uses\n",
    "\n",
    "      max(x, 0) - x * z + log(1 + exp(-abs(x)))\n",
    "\n",
    "  `logits` and `targets` must have the same type and shape.\n",
    "\n",
    "  Args:\n",
    "    logits: A `Tensor` of type `float32` or `float64`.\n",
    "    targets: A `Tensor` of the same type and shape as `logits`.\n",
    "    name: A name for the operation (optional).\n",
    "\n",
    "  Returns:\n",
    "    A `Tensor` of the same shape as `logits` with the componentwise\n",
    "    logistic losses.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If `logits` and `targets` do not have the same shape.\n",
    "  \"\"\"\n",
    "  with ops.op_scope([logits, targets], name, \"logistic_loss\") as name:\n",
    "    logits = ops.convert_to_tensor(logits, name=\"logits\")\n",
    "    targets = ops.convert_to_tensor(targets, name=\"targets\")\n",
    "    try:\n",
    "      targets.get_shape().merge_with(logits.get_shape())\n",
    "    except ValueError:\n",
    "      raise ValueError(\n",
    "          \"logits and targets must have the same shape (%s vs %s)\"\n",
    "          % (logits.get_shape(), targets.get_shape()))\n",
    "\n",
    "    # The logistic loss formula from above is\n",
    "    #   x - x * z + log(1 + exp(-x))\n",
    "    # For x < 0, a more numerically stable formula is\n",
    "    #   -x * z + log(1 + exp(x))\n",
    "    # To avoid branching, we use the combined version\n",
    "    #   max(x, 0) - x * z + log(1 + exp(-abs(x)))\n",
    "    return math_ops.add(nn_ops.relu(logits) - logits * targets,\n",
    "                        math_ops.log(1 + math_ops.exp(-math_ops.abs(logits))),\n",
    "                        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VRAE(object):\n",
    "    \n",
    "    def __init__(self, seq_length, n_z, n_hidden, n_input, train_x, optimizer = tf.train.AdamOptimizer()):\n",
    "        tf.set_random_seed(42)\n",
    "        self.learning_rate = 0.001\n",
    "        self.seq_length = seq_length\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_input = n_input\n",
    "        self.train_x = train_x\n",
    "        self.n_size = 8\n",
    "        network_weights = self._initialize_weights()\n",
    "        self.weights = network_weights\n",
    "        #self.output = tf.placeholder(tf.float32, [seq_length, self.n_size])\n",
    "        self.x = tf.placeholder(tf.float32, [seq_length, self.n_size])\n",
    "        self.sample_z = tf.placeholder(tf.float32, [seq_length, self.n_size])\n",
    "        self.output = tf.zeros([0, self.n_size])\n",
    "        \n",
    "        self.basic_cell = BasicCell(n_hidden[0])\n",
    "        self._initial_state = self.basic_cell.zero_state(tf.float32)\n",
    "        self.state = self._initial_state\n",
    "        with tf.variable_scope(\"RNN\") as scope:\n",
    "            for time_step in range(n_input):\n",
    "                # x_in_t = tf.Variable(self.x[time_step].reshape((1, self.x.shape[1])))\n",
    "                x_in_t = tf.reshape(tf.slice(self.x, [time_step, 0], [1, self.n_size]), (1, self.n_size))\n",
    "                # x_in_t = self.x[time_step].reshape((1, self.x.shape[1]))\n",
    "                if time_step > 0:\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                cell_output, self.state = self.basic_cell(x_in_t, self.state)\n",
    "        \n",
    "        q_mean = tf.add(tf.matmul(self.state, self.weights['W_hmu']), self.weights['b_hmu'])\n",
    "        log_sigma_encoder = tf.add(tf.matmul(self.state, self.weights['W_hsigma']), self.weights['b_hsigma'])\n",
    "        \n",
    "        logpz = -0.5 * tf.reduce_sum(1 + log_sigma_encoder \n",
    "                                           - tf.square(q_mean) \n",
    "                                           - tf.exp(log_sigma_encoder), 1)\n",
    "        \n",
    "        eps = tf.random_normal(tf.shape(log_sigma_encoder), 0, 1, dtype = tf.float32)\n",
    "        \n",
    "        self.z = tf.add(q_mean, tf.mul(tf.exp(0.5 * log_sigma_encoder), eps))\n",
    "        \n",
    "        h0_dec = tf.nn.tanh(tf.add(tf.matmul(self.z, self.weights['W_zh']), self.weights['b_zh']))\n",
    "        \n",
    "        # out= tf.add(tf.matmul(state, self.weights['out']), self.weights['out_b'])\n",
    "        # x_0 = tf.nn.sigmoid(out)\n",
    "        \n",
    "        #self.output = x_0\n",
    "        #rec_loss = tf.nn.sigmoid_cross_entropy_with_logits(x_0, \n",
    "        #                tf.reshape(tf.slice(self.x, [0,0],[1,self.n_size]), (1, self.n_size)))\n",
    "        \n",
    "        #x_t = x_0\n",
    "        \n",
    "        self.basic_cell2 = BasicCell(self.n_hidden[0])\n",
    "        state_x = tf.zeros([1, self.n_size])\n",
    "        out_ = tf.zeros([0, self.n_size])\n",
    "        \n",
    "        with tf.variable_scope(\"gen\") as scope:\n",
    "            for i in range(0, n_input):\n",
    "                if i > 0:\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                (cell_output, h0_dec) = self.basic_cell2(state_x, h0_dec)\n",
    "                x_t_1 = tf.add(tf.matmul(h0_dec, self.weights['W_hx']), self.weights['b_hx'])\n",
    "                state_x = tf.nn.sigmoid(x_t_1)\n",
    "                out_ = tf.concat(0, [out_, state_x])\n",
    "                output_t = tf.squeeze(1 / (1 + tf.exp(-(x_t_1))))\n",
    "                self.output = tf.concat(0, [self.output, tf.reshape(output_t, (1, 8))])\n",
    "\n",
    "        out_ = tf.clip_by_value(out_, 1e-6, 1 - 1e-6)\n",
    "        #reconstr_loss = \\\n",
    "        #    -tf.reduce_sum(self.x * tf.log(1e-10 + out_)\n",
    "        #                   + (1-self.x) * tf.log(1e-10 + 1 - out_),\n",
    "        #                   1)\n",
    "        \n",
    "        logpxz = 0.5 * tf.reduce_sum(tf.pow(tf.sub(out_, self.x), 2.0))\n",
    "        #reconstr_loss = -1 * tf.nn.sigmoid_cross_entropy_with_logits(out_, self.x)\n",
    "            \n",
    "        #logpxz = tf.reduce_mean(reconstr_loss)\n",
    "        \n",
    "        self.cost = tf.reduce_mean(logpxz + logpz)\n",
    "        \n",
    "        self.optimizer = \\\n",
    "            tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "            \n",
    "        init = tf.initialize_all_variables()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(init)\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        all_weights = dict()\n",
    "        all_weights['W_hmu'] = tf.Variable(self.xavier_init(self.n_hidden[-1], n_z))\n",
    "        all_weights['b_hmu'] = tf.Variable(tf.zeros([n_z], dtype=tf.float32))\n",
    "        all_weights['W_hsigma'] = tf.Variable(self.xavier_init(self.n_hidden[-1], n_z))\n",
    "        all_weights['b_hsigma'] = tf.Variable(tf.zeros([n_z], dtype=tf.float32))\n",
    "        all_weights['W_zh'] = tf.Variable(self.xavier_init(n_z, n_hidden[0]))\n",
    "        all_weights['b_zh'] = tf.Variable(tf.zeros([self.n_hidden[0]], dtype=tf.float32))\n",
    "        all_weights['W_hx'] = tf.Variable(self.xavier_init(self.n_hidden[-1], self.train_x.shape[1]))\n",
    "        all_weights['b_hx'] = tf.Variable(tf.zeros([self.train_x.shape[1]], dtype=tf.float32))\n",
    "        \"\"\"\n",
    "        all_weights['W_hmu'] = tf.Variable(tf.zeros([self.n_hidden[-1], n_z], dtype=tf.float32))\n",
    "        all_weights['b_hmu'] = tf.Variable(tf.zeros([n_z], dtype=tf.float32))\n",
    "        all_weights['W_hsigma'] = tf.Variable(tf.zeros([self.n_hidden[-1], n_z], dtype=tf.float32))\n",
    "        all_weights['b_hsigma'] = tf.Variable(tf.zeros([n_z], dtype=tf.float32))\n",
    "        all_weights['W_zh'] = tf.Variable(tf.zeros([n_z, n_hidden[0]], dtype=tf.float32))\n",
    "        all_weights['b_zh'] = tf.Variable(tf.zeros([self.n_hidden[0]], dtype=tf.float32))\n",
    "        all_weights['W_hx'] = tf.Variable(tf.zeros([self.n_hidden[-1], self.train_x.shape[1]], dtype=tf.float32))\n",
    "        all_weights['b_hx'] = tf.Variable(tf.zeros([self.train_x.shape[1]], dtype=tf.float32))\n",
    "        \"\"\"\n",
    "        return all_weights\n",
    "    \n",
    "    def xavier_init(self, fan_in, fan_out, constant = 1):\n",
    "        low = -constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "        high = constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "        return tf.random_uniform((fan_in, fan_out),\n",
    "                             minval = low, maxval = high,\n",
    "                             dtype = tf.float32)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        self.x_sample = tf.placeholder(tf.float32, [seq_length, self.n_size])\n",
    "        state = self.basic_cell.zero_state(tf.float32)\n",
    "        \n",
    "        with tf.variable_scope(\"RNN\") as scope:\n",
    "            for t in xrange(self.x_sample.get_shape()[0]):\n",
    "                x_in_t = tf.reshape(tf.slice(self.x_sample, [t, 0], [1, self.n_size]), (1, self.n_size))\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "                cell_output, state = self.basic_cell(x_in_t, state)\n",
    "        \n",
    "        self.mu_encoder = tf.add(tf.matmul(state, self.weights['W_hmu']), self.weights['b_hmu'])\n",
    "        mu_e = self.mu_encoder\n",
    "        self.log_sigma_encoder = tf.add(tf.matmul(state, self.weights['W_hsigma']), self.weights['b_hsigma'])\n",
    "        l_sig = self.log_sigma_encoder\n",
    "        self.z_t = tf.random_normal(tf.shape(l_sig), mu_e, tf.exp(l_sig))\n",
    "        \n",
    "        z, mu_encoder, log_sigma_encoder = \\\n",
    "            self.sess.run((self.z_t, self.mu_encoder, self.log_sigma_encoder), feed_dict={self.x_sample: X})\n",
    "        return z, mu_encoder, log_sigma_encoder\n",
    "        \n",
    "    def generate(self, Z, latent_variable, t_steps):\n",
    "        \n",
    "        self.z_mu = tf.placeholder(tf.float32, [1,latent_variable])\n",
    "        self.x_gen = array_ops.zeros((1, self.train_x.shape[1]), dtype=tf.float32)\n",
    "        h = tf.add(tf.matmul(self.z_mu, self.weights['W_zh']), self.weights['b_zh'])\n",
    "        \n",
    "        with tf.variable_scope(\"gen\") as scope:\n",
    "            for t in range(0, t_steps):\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "                x_ = tf.reshape(tf.slice(self.x_gen, [t, 0], [1, self.n_size]), (1, self.n_size))\n",
    "                cell_output, h = self.basic_cell2(x_, h)\n",
    "                out = tf.add(tf.matmul(h, self.weights['W_hx']), self.weights['b_hx'])\n",
    "                #out= tf.add(tf.matmul(h, self.weights['out']), self.weights['out_b'])\n",
    "                res = tf.squeeze(1 / (1 + tf.exp(-(out))))\n",
    "                #x_0 = tf.nn.sigmoid(out)\n",
    "                self.x_gen = tf.concat(0, [self.x_gen, tf.reshape(res, (1, 8))])\n",
    "                \n",
    "        x_gen = \\\n",
    "            self.sess.run((self.x_gen), feed_dict={self.z_mu: Z})\n",
    "        return x_gen\n",
    "    \n",
    "    def get_out_weights(self):\n",
    "        weight = self.sess.run((self.weights[\"W_hsigma\"]))\n",
    "        return weight\n",
    "        \n",
    "    def partial_fit(self, X):\n",
    "        cost, opt, out, z = self.sess.run((self.cost, self.optimizer, self.output, self.z), feed_dict={self.x: X})\n",
    "        return cost, out, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0011 cost= 14.690496445\n",
      "Epoch: 0021 cost= 14.648974419\n",
      "Epoch: 0031 cost= 14.498432159\n",
      "Epoch: 0041 cost= 14.366479874\n",
      "Epoch: 0051 cost= 13.793479919\n",
      "Epoch: 0061 cost= 13.614834785\n",
      "Epoch: 0071 cost= 13.640963554\n",
      "Epoch: 0081 cost= 13.392664909\n",
      "Epoch: 0091 cost= 13.825270653\n",
      "Epoch: 0101 cost= 13.039063454\n",
      "Epoch: 0111 cost= 13.243739128\n",
      "Epoch: 0121 cost= 13.222082138\n",
      "Epoch: 0131 cost= 12.546486855\n",
      "Epoch: 0141 cost= 13.058198929\n",
      "Epoch: 0151 cost= 11.950127602\n",
      "Epoch: 0161 cost= 13.912272453\n",
      "Epoch: 0171 cost= 11.794306755\n",
      "Epoch: 0181 cost= 12.593820572\n",
      "Epoch: 0191 cost= 11.626287460\n",
      "Epoch: 0201 cost= 10.007049561\n",
      "Epoch: 0211 cost= 10.355406761\n",
      "Epoch: 0221 cost= 10.361732483\n",
      "Epoch: 0231 cost= 9.706395149\n",
      "Epoch: 0241 cost= 9.524368286\n",
      "Epoch: 0251 cost= 10.236707687\n",
      "Epoch: 0261 cost= 9.787130356\n",
      "Epoch: 0271 cost= 9.993255615\n",
      "Epoch: 0281 cost= 8.569240570\n",
      "Epoch: 0291 cost= 9.383221626\n",
      "Epoch: 0301 cost= 11.422358513\n",
      "Epoch: 0311 cost= 10.942813873\n",
      "Epoch: 0321 cost= 14.740147591\n",
      "Epoch: 0331 cost= 9.887070656\n",
      "Epoch: 0341 cost= 8.957005501\n",
      "Epoch: 0351 cost= 11.100881577\n",
      "Epoch: 0361 cost= 9.191535950\n",
      "Epoch: 0371 cost= 9.629878998\n",
      "Epoch: 0381 cost= 9.931009293\n",
      "Epoch: 0391 cost= 8.204381943\n",
      "Epoch: 0401 cost= 9.207315445\n",
      "Epoch: 0411 cost= 9.401015282\n",
      "Epoch: 0421 cost= 9.288400650\n",
      "Epoch: 0431 cost= 9.238050461\n",
      "Epoch: 0441 cost= 8.403869629\n",
      "Epoch: 0451 cost= 11.762346268\n",
      "Epoch: 0461 cost= 9.223738670\n",
      "Epoch: 0471 cost= 8.295678139\n",
      "Epoch: 0481 cost= 9.970958710\n",
      "Epoch: 0491 cost= 9.142002106\n",
      "Epoch: 0501 cost= 8.812829971\n",
      "Epoch: 0511 cost= 9.580339432\n",
      "Epoch: 0521 cost= 8.920759201\n",
      "Epoch: 0531 cost= 10.012441635\n",
      "Epoch: 0541 cost= 8.968831062\n",
      "Epoch: 0551 cost= 7.927062988\n",
      "Epoch: 0561 cost= 11.757711411\n",
      "Epoch: 0571 cost= 8.580757141\n",
      "Epoch: 0581 cost= 8.976109505\n",
      "Epoch: 0591 cost= 11.474639893\n",
      "Epoch: 0601 cost= 7.923999786\n",
      "Epoch: 0611 cost= 7.631989479\n",
      "Epoch: 0621 cost= 7.750380039\n",
      "Epoch: 0631 cost= 7.533185005\n",
      "Epoch: 0641 cost= 7.149316311\n",
      "Epoch: 0651 cost= 7.430794239\n",
      "Epoch: 0661 cost= 6.487443447\n",
      "Epoch: 0671 cost= 6.769918919\n",
      "Epoch: 0681 cost= 6.901869774\n",
      "Epoch: 0691 cost= 6.776709557\n",
      "Epoch: 0701 cost= 7.744809151\n",
      "Epoch: 0711 cost= 6.129749298\n",
      "Epoch: 0721 cost= 6.585412502\n",
      "Epoch: 0731 cost= 6.338164806\n",
      "Epoch: 0741 cost= 8.867465019\n",
      "Epoch: 0751 cost= 5.932747364\n",
      "Epoch: 0761 cost= 6.501742840\n",
      "Epoch: 0771 cost= 6.809647560\n",
      "Epoch: 0781 cost= 6.121405602\n",
      "Epoch: 0791 cost= 5.869291306\n",
      "Epoch: 0801 cost= 5.919419289\n",
      "Epoch: 0811 cost= 8.045186996\n",
      "Epoch: 0821 cost= 9.948060036\n",
      "Epoch: 0831 cost= 6.053272247\n",
      "Epoch: 0841 cost= 7.299970150\n",
      "Epoch: 0851 cost= 5.857471943\n",
      "Epoch: 0861 cost= 5.966554642\n",
      "Epoch: 0871 cost= 5.913683414\n",
      "Epoch: 0881 cost= 4.820545197\n",
      "Epoch: 0891 cost= 21.345701218\n",
      "Epoch: 0901 cost= 10.321078300\n",
      "Epoch: 0911 cost= 4.919065475\n",
      "Epoch: 0921 cost= 4.790799141\n",
      "Epoch: 0931 cost= 7.654955387\n",
      "Epoch: 0941 cost= 5.578125477\n",
      "Epoch: 0951 cost= 5.510159492\n",
      "Epoch: 0961 cost= 5.350081444\n",
      "Epoch: 0971 cost= 5.308622360\n",
      "Epoch: 0981 cost= 4.710697174\n",
      "Epoch: 0991 cost= 4.548850536\n",
      "Epoch: 1001 cost= 4.709322929\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cPickle as pickle\n",
    "import copy\n",
    "import midi.utils as utils\n",
    "\n",
    "display_step = 10\n",
    "\n",
    "model = VRAE(seq_length, n_z, n_hidden, n_input, train_x)\n",
    "for epoch in xrange(1, n_epochs + 1):\n",
    "    #print('epoch', epoch)\n",
    "    t1 = time.time()\n",
    "    total_loss = 0.0\n",
    "    outputs = np.zeros(train_x.shape, dtype=np.float32)\n",
    "    for i in xrange(n_batch):\n",
    "        x_batch = split_x[i]\n",
    "        cost, out, z = model.partial_fit(x_batch)\n",
    "        outputs[i*seq_length:(i+1)*seq_length, :] = out\n",
    "    if epoch % display_step == 0:\n",
    "        #utils.midiwrite('VRAE_100.midi', outputs, dt=0.5)\n",
    "        print \"Epoch:\", '%04d' % (epoch + 1), \\\n",
    "                \"cost=\", \"{:.9f}\".format(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def convert2Midi(out):\n",
    "    output = []\n",
    "    for o in out:\n",
    "        count_dict = collections.Counter(o)\n",
    "        maxavg = max(count_dict.items(), key=lambda x:x[1])[0]\n",
    "        output.append([1 if x > 0.5 else 0 for x in o])\n",
    "    return np.asarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z, mu_encoder, log_sigma_encoder = model.transform(split_x[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_gen = model.generate(z, n_z, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_gen_conv = convert2Midi(out_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "packed = np.packbits(out_gen_conv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_gen_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</th><th>Position</th><th>Xgsition</th><th>Xgsition</th><th>Xgsition</th><th>Pgsitimn</th>4tb>@geheh</raead|+v`llqif;\"ehde`odaf>tf<@gsmtamf(\\'pmv0eb|,sallae`o4pivigp=60bgycdxge`ccaaeifejgxcexeu`ov`bgaf'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([str(unichr(x)) for x in packed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "packed2 = np.packbits(split_x[4].astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</th><th>Position</t'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([str(unichr(x)) for x in packed2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fbf938f6a50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHv5JREFUeJzt3X20HFWZ7/HvL7xJomBAE0ZeAnHkRQQVkRFQyTjKiDAB\nR2VQ0QCjLq86sBS9id7rzcS1dAzjvc7M8spcBJnAKBKcYYgzKKikRVRAIfIWgVEgE5AcJISXyFqI\n5Ll/1D5QfeicU9196tTZ3b/PWr1O9+6qrl11dtezn13VVYoIzMzMRs1ougJmZja9ODCYmVkbBwYz\nM2vjwGBmZm0cGMzMrI0Dg5mZtXFgMJskkrZImt/DfHtKelSS6qjXZJK0WtJp6fkiST9suk42+RwY\nzJi0nVxPPwqKiPURsVPk+aOiHOtsE3BgsIEnaZsqk9H/Tm7a9/jHU3E72RBwYLBaSTpE0o2SHpG0\nUtI3JH2m9P5xktZI2iTpGkkHld67W9KZkm5K718kafsu5v3vkm4CNkuaIWmxpF+mYZtbJZ2Qpt0f\nOBs4XNJjkh5K5dtL+oKkdZLul/RlSTuUlvEJSb+WdK+kUxknsKQhmM9Jui5ti0slPT+9Ny8NQ81I\nr0+RtDbV85eSPlD6nKMkrZf0MUkjku6TdErp/Z0kXSDpgbQN/scE/58tkj4k6U7gzlR2hKTr03a9\nTtLh432GDaCI8MOPWh7AdsA9wEeAbYC3Ak8An0nvvxIYAQ6l6G2/B7gb2C69fzdwLTAXeD6wFvhA\nF/PeCLwI2CGVvQ2Ym56/A9hcer0IuHpM/b8I/BuwMzALuAz4bHrvzcD9wAHAjsDXgKeA+VvZFquB\n9aXpvwlcmN6bl+adkV4fA+ydnr8O+C3wivT6KOBJYGnapsek93dO718AXArMTJ97B3DqOP+jLcAV\naR13AGYDDwHvoug4npRezy6tx2lb22Z+DMaj8Qr4MbiPtFNbP6bsh6XA8GVg2Zj3bwdel57fDbyz\n9N5y4MtdzLtogvqtAf4sPe8UGDYD+5ReHw7clZ6fB3yu9N5LKgSG8vQHUARJjQ0MHea9FPir9Pyo\nFAhmlN4fAQ5LO/IngP1K730AuGqcbbAFOKr0+mTg2jHT/Bh4b2k9HBgG/OGhJKvTi4D7xpStLz2f\nB5wp6aH02ATskeYbNVJ6/jjw3C7mvbe8YEnvLQ09bQIOBF7QqeKSXkjR675hdBnAt4FdS+tWXpd1\nTHyMYez023VavqRjJP1E0sZUz2PGTLcxIraUXo9ulxcA2wL/NWY5u6fPvTUNlT0q6cjSNOXt9KI0\nT9nTn2HDYdumK2AD7X6evUPZE/hler6eYmjmb3r47CrzPj3mL2kv4BzgjyPiJ6lsDc/szMceH3iQ\nYod7YETc3+Gz76dYl1HzOnzGWGOn/11azl6lem5PMcx0MnBZRGyRdCnVDmw/SDHMNI8iexpdzn0A\nEfGyrcxXrvevKYbcyvaiCIo2JJwxWJ1+Ajwl6cOStpF0PMWQx6ivAB+UdBiApFmS3iJpVoXP7nbe\nWRTDJg+mA9GnAuUd5Qiwh6TtAKIYK/kK8Hcpe0DS7pKOTtOvBE6RdICkmcD/qlDnkyXtn6ZfBlyS\nlgPP7Pi3T48HU1A4Bji6w2c9S8oiLgE+K+m5kuYBHwUurDJ/cjnwEkknpf/ZX1AMe32ri8+wzDkw\nWG0i4kngz4H3AZsoDmh+i2IcnIi4AXg/8KU0VHMnxbj10x8xzmd3NW9E/AL43xQHszdQDCNdU5rk\nKuA2YIOkB1LZEors5lpJDwNXAvumz/sO8HdpvjuB70+4QYod9AqKXvn2wBlj6xsRm4HTgUvSep1E\ncdB7POV1/SuKTOcu4GrgnyPi/IrzEhEPAccBH6fIQD4OHBsRmzpNb4NJz3RYzOon6Vrg7IhY0XRd\nppKk1RRnIX216bqYTcQZg9VK0uslzU3DEouAg4DvNF0vM9s6H3y2uu1HMR4/k2J4420RMTL+LAPJ\nqbllw0NJZmbWxkNJZmbWJsuhJElOc8zMehARE/4mxhmDda2fn9ovXbq08Z/71/WYqnXLXdP/p2Fu\nl1U5MJiZWZssh5LM+qEab5S2bNmy2j7bbKo4Y7AptWDBgqarYPYsg9wue1m3LE9X9cHnZuXYZgZJ\nnRnPVMi9/QzA9p9wBTyUZGZTKvcd6zDwUJKZmbVxxmCWmdyHYqw5VbM1ZwxmZtbGGYN1zWPE1g9n\nPNOfMwYzM2vjjMG6lnuPL/eMJ/ftb9OfMwYzM2vjjMG65h53s7z9rW7OGMzMrE22GUPOvY7ce3xm\nNticMZiZWZtaMwZJ5wHHASMRcXAqmw1cDMwD7gFOjIhH0nufBE4Dfg+cERFX1lk/G065Z2w5Z8vg\n7Z+DWq+uKum1wGbgglJgWA5sjIizJC0GZkfEEkkvBb4GvBrYA/ge8JLoUEFfXdX6MQxfbLNOJFW6\numqtQ0kRcQ2waUzx8cCK9HwFcEJ6vhD4RkT8PiLuAf4TOKzO+pmZ2bM1cfB5TkSMAETEBklzUvnu\nwE9K092XymyacY+7WR6KsbpNh7OS3ErMzGrQarVotVpdz9dEYBiRNDciRiTtBjyQyu8D9ixNt0cq\n6yjnXkfuPb7ceftbP4ah/UzF6apKj1GrgFPS80XAZaXykyRtL2kf4A+B66egfmZmVlL36apfBxYA\nu0r6L2Ap8HngEkmnAeuAEwEiYq2klcBa4EngQ53OSCp9dp1VN5u2cs6WB0HO27/qfrPW01Xr4tNV\nm5VjmynLvVOR+/a35lQ9XXU6HHw2m1K571gd2JqV+/avwpfEMDOzNs4YzDKTe4/bpj8HBhs6wzAU\nMJ05sE1/HkoyM7M2zhhs6OTeY3XG06yc20/VtuOMwczM2jhjMMtMzj1Wy4MzBjMza+OMwbrmMe5m\nOWNo1jC0f2cMZmbWxhmDdS33Husw9PisPjm3f5+VZGZmPXHGYEMn5x4f5J/x5L79h4EzBjMza5Nt\nxpBzryP3Hl/u9Tez8TWWMUg6Q9It6XF6Kpst6UpJd0i6QtLOTdXPzOohKevHMGgkMEg6EPhL4FDg\nFcBxkl4MLAG+FxH7AVcBn2yifmZmw6ypoaQDgOsi4gkASVcDfw4spLhHNMAKoEURLMwsyXkY1fLQ\n1FDSrcDr0tDRTOAtwJ7A3IgYAYiIDcCchupnZja0GskYIuJ2ScuB7wKbgTXAU50m3dpnDMtYn02+\n3Hvcubf93Lf/MGjsrKSIOB84H0DSZ4H1wIikuRExImk34IGm6mdmlrtWq0Wr1ep6vsYCg6QXRsRv\nJO0FvBV4DbAPcAqwHFgEXNZU/Wzrcu/x5d7jtmYNQ/tRU1/ydMB5F+BJ4KMR0ZK0C7CS4njDOuDE\niHi4w7x575ky58Bg/XD7aVZETLgCjQWGfjgwNCvHNlOW+xc7d7m3n5xJqhQYfEkMMzNrk+0lMcx6\nlXuP1RlPs4Zh+ztjMDOzNs4YzDKTe8Zj058zBjMza+PAYGZmbTyUZJaZYTj4OZ3lPJTnez6bmVlP\nnDHY0Mm9x51zj9Xy4IzBzMzaOGOwrrnH3Sxvf6ubMwYzM2uTbcaQc68j9x6fmQ02ZwxmZtYm24zB\nrFfO2MzGl21g8JfbhlXOw6iWh3GHkiRtI+kLU1UZMzNr3rgZQ0Q8Jem1dSxY0ieBk4GngFuAU4FZ\nwMXAPOAeilt7PlLH8q137rE2K/ds2e1n+pvw1p6SzgZ2By4BfjtaHhH/2vNCpXnAamD/iPidpIuB\ny4GXAhsj4ixJi4HZEbGkw/xuWQ3yF7tZDgzWq6q39qxyjOE5wEbgDaWyAHoODMCjwO+AWZK2ADsC\n9wGfBI5K06wAWsCzAoNZP3LfsZrVbcKMobYFS+8H/g/wOHBlRLxH0qaImF2a5qGI2KXDvO5yNCj3\nHp8DQ7Nybz85q5oxTPg7Bkn7Svq+pFvT64Ml/c8+Kzcf+CjFsYQXUWQO76bIRMrcgsxsWpGU7aOq\nKj9w+wrFEM+TABFxM3BST1v0GYcCP4qIhyLiKeBS4AhgRNJcAEm7AQ/0uRwzM+tSlcAwMyKuH1P2\n+z6XewfwGknPURHG/gRYC6wCTknTLAIu63M5ZmaTKiKyfVRV5eDzg5JeTBrWkfR24P7eNmkhIm6S\ndAFwA8XpqmuAc4DnASslnQasA07sZzlmZta9KqerzqfYaR8BbALuBt4dEevqr95W6+RjDw3ywUMb\nZrmfvFDl4HPls5IkzQJmRMRj/VasXw4MzXJgsGE2DIFhwqEkSbsCS4HXAiHpGuAzEbGx/ypajgbg\ni9F0FcymtSpDSd8Frgb+ORW9G1gQEW+suW7j1cnf7AblvmN1YLNhVfV3DFUCw60R8bIxZbdExEF9\n1rFnDgzNyn3H5MBgw2oyL4lxpaSTgJXp9duBK/qpnFmTvGM1G99WMwZJj1GcoiqKq55uSW/NADZH\nxE5TUsPOdfM3u0HesZrladKGkqYjSZFjvUflPpSRu5zbDuTffnLf/jmbzKEkJB0M7F2evp/LbpuZ\n2fRV5XTVrwIHA7fxzHBSv5fdNmtM7j3u3OW+/Ych46mSMbwmIl5ae03MzGxaqBIYrpf00ohYW3tt\nupB7r8OsV8PQY7VmVQkM/wRcK+l+4AmKs5QiIg6us2JmZtaMKoHhXOBk4BaeOcZgQ8w91mblni3n\n3n5y3/5VVAkMv4mIVbXXxMzMpoUqgWGNpK8D36IYSgJ8uqrlaxh6fGb9qBIYdqQICEeXyny6qpkN\npZyHwqp2ihr55bOkfYGLeeaSG/OBTwMXpvJ5wD3AiRHxSIf58/3PDICcvxjgjKFpubefnE3m1VXP\nJ93WsywiTuu9em2fPwO4F/gj4CPAxog4S9JiYHZELOkwj1tWg3L/YjswNMvtp1mTdUmMfy89fw7w\nVuDXvVaqgzcCv4qI9ZKOB45K5SuAFvCswGBmZvXpeigp9fCviYgjJqUC0nnAzyLibEmbImJ26b2H\nImKXDvPk3eXIXO49PrN+DEPGMKOHz30JMKeH+Z5F0nbAQuCSVDR2j+M9kJnZFKtyEb3yfRkC2AAs\nnqTlHwPcEBEPptcjkuZGxIik3YAHJmk5ZmZW0YSBISKeV+Py3wlcVHq9CjgFWA4sAi6rcdlmZtZB\npWMMknanOIW0fD+Gq/tasDQTWAfMj4jHUtkuFLcQ3TO9d2JEPNxhXg8xmWXKx6iaM5mnqy4H/gJY\nCzyViiMiFvZdyx45MJjly4GhOZMZGO4ADo6IJ8adcAr51p7Nynnbg7e/Da+qgaHKWUl3Adv1XyUz\nM8tBlR+4PQ78XNL3ab+I3um11aqC3Ht9Oct92+fe4/b2t7pVCQyr0mNayblx5f7FNrPB1shF9Prl\nYwzWj5zbDuTffnLf/jmreoyhSsZgNlBy37Ga1a2XS2KYmdkAq5wxSJoZEY/XWZluuNdnZlaPCTMG\nSUdIWgvcnl6/XNKXa6+ZmZk1okrG8EXgT0lnJkXETZJeX2utbFrzwcNmOVtu1jBs/0rHGCJi/Zii\npzpOaGZm2auSMayXdAQQ6f4JZwC/qLdaZvUZhh6fWT+qZAwfBD4M7A7cB7wC+FCdlTIzs+ZUyRj2\ni4h3lwskHQn8qJ4qmdXLx0jMxlfl6qo3RsQhE5VNJV92u1nesVo/PJTXrL5++SzpcOAI4IWSPlZ6\naydgm/6rZ2Zm09F4Q0nbA89N05Rv7/ko8PZ+FyxpZ+Bc4GXAFuA04E7gYoq7xd1DcQe3R/pdlplN\nH844m1M1W6sylDQvItZJei5ARGzuv3og6Z+AH0TE+ZK2BWYBnwI2RsRZkhYDsyNiSYd53bIa5C+2\nWZ4m8w5uLwMuBHZJRQ8CiyLi1j4qtxOwJiJePKb8duCoiBiRtBvQioj9O8zvPVODcg8MHuNuVu7t\nJ2eTeQe3c4CPRcS8iJgHnJnK+rEP8KCk8yXdKOkcSTOBuRExAhARG4A5fS7HzMy6VOV01VkRsXr0\nRUS0JM2ahOUeAnw4In4m6YvAEmBsV8JdC7Mx3OO2ulUJDHdJ+jTFcBLAyRT3ge7HvcD6iPhZev0v\nFIFhRNLc0lDSA30ux8xsaLVaLVqtVtfzVTnGMBtYBrw2Ff0Q+OuI2NT10to/9wfA+yPiTklLgZnp\nrYciYrkPPk9f7rE2K/djJG4/zZm0g891kfRyitNVt6PIQE6l+H3ESmBPYB3F6aoPd5jXLatB/mI3\ny4HBejWZZyXtC3wc2JvS0FNEvKHPOvbM93w2y1fO393cTWZguAn4R+AGSpfbjogb+q1krxwYzPKV\n83c3d1UDQ5WDz7+PiLMnoU5mZtl3jIYhsFXJGP6a4uygS4EnRssj4qFaazZ+nQb/P2O2FcOwY7J6\nTOZQ0t0diiMi5vdauX45MNgwc2CwXk37s5L64cBg/cixzZd5KMZ6NZmXxDAzsyFS5eDztJRzryP3\nHl/uvP2tH8PQfpwxmJlZm/Hu4DburTsj4sbJr46ZTSTnbHkQ5Lz9+75Rj6TVHd8ohH/53LthSEWt\nPjm3fWuWz0qy2uTYZgZJ7h2L3NvPAGz//n75LGlX4F3A6F3UfgF8vckft5mZWb22evBZ0gHArcCr\ngDuB/wReDdwq6Vm32zQzs8Ew3jGGbwIrI2LlmPK3Ae+KiLdNQf068lBSs3IfCsjdAAxlNF2FvgzA\n9u/9GIOkOyJiv27fmwoODM3yF9v64fbTrH6PMfy2x/fMpjXvmMzGN15gmCPpYx3KBbywpvqYmVnD\nxgsMXwGet5X3zu13wZLuAR4BtgBPRsRh6f7SFwPzgHsobu35SL/LMhskuWc8Nv01ec/nu4BXRcSm\nUtlyYGNEnCVpMTA7IpZ0mNffjAZ5x2TDLPehvH4PPv/DBB9+eo/1Gv38u4FDI2Jjqex24KiIGJG0\nG9CKiGedGuvA0CwHBhtmwxAYxhtKqvuezgF8V9JTwP+LiHOBuRExAhARGyTNqbkOZmY2xlYDQ0Ss\nqHnZR0bE/ZJeCFwp6Q6KYNFWjZrrYGbWlZwy5larRavVevr1smXLKs033lDSqvFmjIiF1as3QSWk\npcBm4H3AgtJQ0uqIOKDD9Pn8ZwZQTl8MM3tG1YvojTeUdDiwHrgIuI7iNNVJIWkmMCMiNkuaBRwN\nLANWAacAy4FFwGWTtUyzUbmPEefOHYvpb7yMYRvgTcA7gYOB/wAuiojb+l6otA9wKcVQ0bbA1yLi\n85J2AVYCewLrKE5XfbjD/G5ZDcr9i+3A0Kzc20/OJvWy25J2oAgQfwssi4gv9V/F3jkwmOXLgaE5\nkzGUNBoQjqUICnsD/0DR0zczswE13lDSBcDLgMuBb0TErVNZsfE4Y7B+uMdqw6rvoSRJW3jmYnnl\niURxa8+d+q5lj3xrT7N85fzdhfy/v30NJUXEVm/iY2Zmg2vcYwzTWe5R25qTe4/VmpVz+6m633RW\nYGZmbbLNGKw5OfeYwNlm03JvP8PAGYOZmbVxxmBm1oVhyDidMZiZWRtnDDZ0PMZt/ci5/fisJDMz\n64kzBrPM5D7GnXOPG/Lf/lU4MJhlJvcdq01/HkoyM7M2zhhs6OQ+FOCMwerWaMYgaYakG0fvLy1p\ntqQrJd0h6QpJOzdZPzOzYVTpDm61LVz6KPAqYKeIWChpObAxIs6StBiYHRFLOsznLlOD3GM1y1PV\n+zE0ljFI2gN4C3Buqfh4YEV6vgI4YarrZWY27Jo8xvBF4BNAebhobkSMAETEBklzGqmZ2TTmYyRW\nt0YyBknHAiMR8XOKO8JtjVuQmdkUaypjOBJYKOktwI7A8yRdCGyQNDciRiTtBjywtQ9YunTp088X\nLFjAggULaq7y5Mm9x5d7/c2GRavVotVqdT1fowefASQdBZyZDj6fRXHweflEB5+brnc/vGO1YZbz\ndzd3VQ8+T7ffMXweWCnpNGAdcOLWJvTOtTn+YpsNtsYzhl74dNVm5dhmzCzfjMEy4GzN+pF7x2IY\n2r8Dg3Ut9y+2WT9ybv++H4OZmfXEGYN1bRhSaatPzj3uYeGMwczM2jhjsK65x9csZ2xWN2cMZmbW\nxhmDWWZyz9ic8Ux/zhjMzKxNthlDzr2m3HtMudc/57ZjNhWcMZiZWZtsM4bce605y73H7bbTrNzb\nT878y2czM+uJA4OZmbXJdijJrFe5D2V4KKxZw7D9nTGYmVkbBwYzM2vTSGCQtIOk6yStkXSbpM+l\n8tmSrpR0h6QrJO3cRP3MzIZZY7f2lDQzIh6XtA3wI+BMYCGwMSLOkrQYmB0RSzrMGzmPE+c+Rpnz\ntjfr1wB8fydcgcaGkiLi8fR0h1SPTcDxwIpUvgI4oYGqmZkNtcbOSpI0A7gBeDHwjxGxVtLciBgB\niIgNkuaMM/8U1dTG8rZvljM2q1tjgSEitgCvlLQTcIWkBcDYFu9vgJnZFGv8dwwR8aiky4FDgZHR\nrEHSbsADDVfPOnCPtVm5Z2xuP9NfU2clvWD0jCNJOwJvAtYAq4BT0mSLgMuaqJ+Z2TBr5KwkSQdR\nHFwWRXC6MCK+IGkXYCWwJ7AOODEiHu4wv7scDcq9x5d7jzt3ubefnEmqdFZSY6er9sOnq9owy7nt\nW7OqBgb/8tnMzNo0fvC5V+51N8c9VutH7t/dYWj/zhjMzKxNthmDWa/cY21W7vXPvf1U4YzBzMza\nOGOwoeMea7Ny3/4519/3fDYzs55kmzEMQ9S2enj7Nyv37Z/zvqcqZwxmZtYm24wh915HzrztmzUM\nPVZrljMGMzNrk23GYNYr97jNxufAYGZTykOR05+HkszMrI0Dg3UtInp+rF69uq/5J+MhKetHU1qt\n1qR8TtP//37b5TBwYLApNVk7F5t6g/y/G+R160W2gaHpHkadj6VLlzZeh0HuMeX+f7NmNf3966dd\nVpVtYDAzs3pke2vPputgZpajGNR7PpuZWX08lGRmZm0cGMzMrE12gUHSmyXdLulOSYubrk8/JJ0n\naUTSzaWy2ZKulHSHpCsk7dxkHXslaQ9JV0m6TdItkk5P5YOyfjtIuk7SmrSOn0vlA7F+AJJmSLpR\n0qr0eiDWTdI9km5K/7vrU9lArBuApJ0lXSLpF6lt/lG365dVYJA0A/gS8KfAgcA7Je3fbK36cj7F\nupQtAb4XEfsBVwGfnPJaTY7fAx+LiAOBw4EPp//VQKxfRDwB/HFEvBI4GHiDpCMZkPVLzgDWll4P\nyrptARZExCsj4rBUNijrBvD3wOURcQDwcuB2ul2/ps+x7fL87dcA3y69XgIsbrpefa7TPODm0uvb\ngbnp+W7A7U3XcZLW89+ANw7i+gEzgeuBlw7K+gF7AN8FFgCrUtmgrNvdwK5jygZl3XYCftWhvKv1\nyypjAHYH1pde35vKBsmciBgBiIgNwJyG69M3SXsDrwCupWicA7F+aahlDbABaEXEWgZn/b4IfAIo\nn7Y4KOsWwHcl/VTS+1LZoKzbPsCDks5Pw4DnSJpJl+uXW2AYRlmfTyzpucA3gTMiYjPPXp9s1y8i\ntkQxlLQH8DpJCxiA9ZN0LDASET8HxjvnPbt1S46MiEOAt1AMcb6OAfi/JdsChwD/N63jbylGVrpa\nv9wCw33AXqXXe6SyQTIiaS6ApN2ABxquT88kbUsRFC6MiMtS8cCs36iIeBS4HDiUwVi/I4GFku4C\nLqI4fnIhsGEA1o2IuD/9/Q3FEOdhDMb/DYpRlPUR8bP0+l8oAkVX65dbYPgp8IeS5knaHjgJWNVw\nnfol2ntlq4BT0vNFwGVjZ8jIV4G1EfH3pbKBWD9JLxg9s0PSjsCbgDUMwPpFxKciYq+ImE/xHbsq\nIt4DfIvM103SzJTFImkWcDRwCwPwfwNIw0XrJe2biv4EuI0u1y+7Xz5LejPFUfcZwHkR8fmGq9Qz\nSV+nOLi3KzACLKXowVwC7AmsA06MiIebqmOv0hk6V1N86SI9PkVxkHYl+a/fQcAKiqA+gyIr+oKk\nXRiA9Rsl6SjgzIhYOAjrJmkf4FKK9rgt8LWI+PwgrNsoSS8HzgW2A+4CTgW2oYv1yy4wmJlZvXIb\nSjIzs5o5MJiZWRsHBjMza+PAYGZmbRwYzMysjQODmZm1cWCwoZcuU/zfSq//QNLKmpZ1rKSl47x/\nsKTz6li2WVX+HYMNvXSRv29FxEFTsKzVwEmjFzQbZ5oT0yUbzKacMwYz+Btgfroa5fJ0yZVbACQt\nknRpusnJXZI+IunMNO2PJT0/TTdf0rfTFTt/ULokwdMk7QFsNxoUJL0j3cRojaRWadLvAO+ofa3N\ntsKBway4+uSvIuKQiBi9K2A5lT4QOIHiYmufBR5NV668FnhvmuYc4CMR8WqKy1Wf3WE5RwI3ll5/\nGjg6XaF1Yan8euD1/a2SWe+2bboCZhlYHRGPA49L2gT8eyq/BTgoXYztCOASSaMXRNyuw+fMA+4v\nvb4GWJGOZ/xrqfzXwN6TWH+zrjgwmE3sidLzKL3eQvEdmgFsSlnERJ6+km5EfEjSq4HjgBskHRIR\nm9I0PvhnjfFQkhk8Bjyv15kj4jHgbklvHy2TdHCHSddR3FZxdJr5EfHTiFhKcX38PdNbf5CmNWuE\nA4MNvYh4CPiRpJslLZ9o8q2Unwz8paSfS7qV9mMGo34EvKr0+m/TMm8GfhwRN6fyw4AfdrEKZpPK\np6uaTSFJ3wfene67u7VpWhSnq+Z6FzHLnDMGs6n1BeCDW3szDUH90kHBmuSMwczM2jhjMDOzNg4M\nZmbWxoHBzMzaODCYmVkbBwYzM2vjwGBmZm3+PzmNTogLe+53AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbf9390ea10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure()\n",
    "extent = (0, 0.5 * len(out_gen_conv)) + (21, 109)\n",
    "imshow(out_gen_conv, origin='lower', aspect='auto',\n",
    "                         interpolation='nearest', cmap=cm.gray_r,\n",
    "                         extent=extent)\n",
    "xlabel('time (s)')\n",
    "ylabel('MIDI note number')\n",
    "title('generated piano-roll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fbf93778250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiaiVJRERErSSJiIiolSQRERG1/j89cxpSCu+irQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbf9391ed10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure()\n",
    "extent = (0, 0.5 * len(split_x[1])) + (21, 109)\n",
    "imshow(split_x[1], origin='lower', aspect='auto',\n",
    "                         interpolation='nearest', cmap=cm.gray_r,\n",
    "                         extent=extent)\n",
    "xlabel('time (s)')\n",
    "ylabel('MIDI note number')\n",
    "title('source piano-roll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
